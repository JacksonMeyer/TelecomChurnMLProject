{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Name: Jackson Meyer\n",
    "\n",
    "2. Problem: I have a data file that has customer information for a telecommuncations company. I am trying to create a model that can predict with a good accuracy whether or not a customer is likely to leave, which we call churn. \n",
    "\n",
    "3. Data: Target Feature : Churn - Binary. Yes or No. Whether or not the customer stopped doing business with the company\n",
    "         Customer ID - removed from predictor columns. Used for identifying customer, but has no impact on their decision to            churn or not.\n",
    "         Predictor Variables: BINARY(Default= Yes OR No). \n",
    "         Gender - Binary. Male or Female. Important for seeing demographics of customers churning.\n",
    "         SeniorCitizen - Binary. Important for seeing whether or not age has an impact on churning. \n",
    "         Partner - Binary. Important for seeing whether Romantic relationships and increase in combined income impacts                  churning. \n",
    "         Dependents - Binary. Important for seeing whether having dependnets and thus increased expenditures has an impact on            churning.\n",
    "         Tenure - Numerical. Number of months the customer has stayed with the company. Import for seeing if there are hotspots          on time with the company that dictate churning. \n",
    "         PhoneService - Binary. Important to see if being a member of the phone service negatively or positively impacts                churning.\n",
    "         Multiple Lines - Binary. Yes or No/No phone service. Important to see if customers with one lines or multiple lines            are more content and the impact on churning.\n",
    "         InternetService - Internet service provided. DSL, Fiber Optic, No. Important to see whether or not purchasing DSL or            Fiber Optic has a greater impact on churning or if no internet service at all has the greater impact. \n",
    "         OnlineSecurity - Binary. Yes or No/No internet service. Important to see whether or not having extra security measures          and an increased sense of safety with the company impacts churning.\n",
    "         OnlineBackup - Binary. Yes or No/No internet service. Important to see if extra security measures with backup storage          for computers or other devices with access to the internet has impact on churning. \n",
    "         DeviceProtection - Binary. Yes or No/No internet service. Important to see whether or not backing up your devices              gives a sense of reassurance and the relationship it has with churning.\n",
    "         TechSupport - Binary. Yes or No/No internet service. Important to see what kind of relationship exists between                  having/not having a positive relationship with tech support workers at the telecom company and churning. \n",
    "         StreamingTV - Binary. Yes or No/No internet service. Important to see whether or not having access to a TV that can            stream shows dictates churning.\n",
    "         StreamingMovies - Binary. Yes or No/No internet service. Important to see whether or not being able to stream movies            on demand has a impact on churning.\n",
    "         Contract - Month-to-month, One year, Two year. Important to see if the company should focus more on one type of                contract than the others because it has a greater impact on less overall churning. \n",
    "         PaperlessBilling - Binary. Imporant to see if the company should use paper or paperless billing for less churning. \n",
    "         PaymentMethod - Electronic Check, Mailed Check, Bank Transfer (Automatic), Credit Card (automatic). Important to see            if there is any payment methods the company should move away from or encourage more of with their customers to have            less churning. \n",
    "         MonthlyCharges - The amount charged to the customer monthly. Important to see what price ranges for monthly payments            are casuing the most churning and which ones are causing the least.\n",
    "         TotalCharges - The total amount charged to the customer throughout their entire time with the company. Similar to the          MonthlyCharges, but sees if there is a possible 'limit-like' behavior for total money spent. In other words, does              there reach a amount where the customer doesn't want to spend any more. \n",
    "            \n",
    "\n",
    "4. Data Preparation: I had to do a lot of manipulation to the data. The first thing I did was remove any null values. I notice that there were several values in the 'TotalCharges' column that were missing but had a space for a value. Before removing all null values, I converted all 'TotalCharges' values equal to ' ' to null values. Next I noticed that there were 6 columns that had values (Yes, No, No internet service) and 1 column with (Yes, No, No phone service). To make these categorical columns binary, I changed all values that equaled 'No internet service' or 'No phone service' to just 'No'. There was also one categorical column 'SeniorCitizen' that had values 1 and 0. I converted all values equal to 1 to 'Yes' and 0 to 'No'. Next I wanted to scale all the numerical values using a StandardScaler. However, I did not want to group tenure as a numerical value with 'MonthlyCharges' and 'TotalCharges'. I did not think it made sense to scale tenure, so I made it a categorical variable by converting the unit of months to years, and created 6 clusters, 0-1 years, 1-2 years,.... all the way to 5+ years. I then used a standard scaler on the 'MonthlyCharges' and 'TotalCharges' to normalize the data. Now I needed to finalize all my predictor variables by making them usable by my several models. The numerical predictors were already set, so I divided the categorical variables into binary ones and non-binary ones, or rather variables with 2 unique values and variables with >2 unique variables. I used a label enconder on the binary elements to convert to 2 seperate and distinct integer values. I did not want to use a label encoder for non-binary categorical variables, so instead I created dummy variables, and replaced the original columns by dropping them and merging the new dummy columns with their values. I then used train_split_test to create and created x_test, y_test, x_train, y_train to use with my models.         \n",
    "\n",
    "5. Metrics: For each of the models I create, I will be testing them with a confusion matrix and accuracy score . We are dealing with a classification problem and these metrics work well with categorical variables. We would not use a r2_score or MSE because those metrics measure how close predictoins are for continous variables, but not if the predictions were correct or incorrect for categorical variables. For the predictions that are incorrect, I do a breakdown comparing ones that incorrectly predict they will not churn, when in fact they do, and vice versa. That is done very easily with a confusion matrix. I will use that to see if the model predicts that the company would lose custoemrs when they think it wouldn't or if the model predicts they lose will lose customers when they actually wouldn't. For this problem, it would be worse if the company was predicting customers to not churn, when they actually will.  \n",
    "\n",
    "6.  Baseline Performance: The baseline I used for my metrics was to assume that every customer would stay. This is a good baseline because it represents what would happen if you assume everything is going well and the company does not need to change anything. We can then compare that accuracy score to ones generated from our models to see which ones yield better results than essentially changing nothing. \n",
    "\n",
    "7. Model Planning and Execution: I will used four learning algorithms models 1.K-Nearest Neighbor, 2. DecisionTree, 3.Random Forest, 4. Perceptron. For K-Nearest Neighbor I will tune the value for K and make it weighted. This will allow me to find a optimal k value and see the impact on using weight distance to find nearest neighbors. For decision tree I will tune criterion and max_depth. It will allow me to see results based on Gini impurity vs Entropy and if shorter or longer trees perform better. For random forest, I will tune the same parameters as decision tree with addition to n_estimators - the number of trees in the forest. Given that random forest is a collection of decision trees, I want to see if tuning the same parameters has a direct relationship or not and then look at number of trees. For perceptron, I will tune the learning rate(eta0). The learning rate is default at 1 . I will see if decreasing this value increases our accuracy.      \n",
    "\n",
    "8. Results: After tuning the parameters, the models had significant changes. In the beginning, most of the models were very close to the baseline accuracy score. Sometimes the random forest and perceptron performed better. When changing the parameters, all of the models performed better on average. The KNN optimal k value was always much greater than 5 and the weighted knn perfomred better than the nonweighed version. The Decision Tree had a default max depth of none. Normally the max depth would be ideal in between 1-10 and the entropy criterion performed slighly better than gini criterion, although the change in depth was more important to increasing accuracy score. The same was said for the Random forest. The entropy criterion performed better and the depth was always best in between 1-10. The n estimators variable was quite random. It ranged between 10-50 for ideal values depending on the split of the test and training data for the model. While it was not consistent, when an optimal value was found the accuracy scores were always much higher.     \n",
    "\n",
    "9. Recommendation: The company should used a random forest model with tuned parameters. If the baseline for not doing anything gives us a 73% accuracy score, the random forest with tuned parameters produces an accuracy score that averages over 80% consistently. That is atleast a 7% increase in accuracy and would lead to an increase in the rate at which the company retains customers which is directly correlated to the success of the company. I have included accuracy scores and confusions matrices as well as a bar chart comparing before and after tuning the models and their respective metrics.  \n",
    "\n",
    "10. Insights: For all the confusion matrices produced, it appears that most of the time there is a signifcantly more amount of predictions that they will churn when in fact they will not compared to predictions when they think they won't churn when in fact they will. This means that the company would actually do better than what our models predict in terms of accuracy more of the time. Since more of our wrong predictions are benefical rather than bad for the company, you could assume that our model is better than doing nothing, but still possibilty and underapproximation of how well it does! \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# put vehicles data into a dataframe\n",
    "telco_data = pandas.read_csv(\"Telcom_churn.csv\")\n",
    "\n",
    "# Predictor and target variables\n",
    "predictors = telco_data.columns.tolist()\n",
    "predictors.remove('Churn')\n",
    "predictors.remove('customerID')\n",
    "target = ['Churn']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# drop any rows with null predictor column values\n",
    "telco_data['TotalCharges'] = telco_data['TotalCharges'].replace(' ',numpy.nan)\n",
    "telco_data = telco_data.dropna(subset=predictors)\n",
    "\n",
    "# change no phone service and no internet service to no\n",
    "no_int_ser_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport','StreamingTV', 'StreamingMovies']\n",
    "for i in no_int_ser_cols : \n",
    "    telco_data[i]  = telco_data[i].replace(to_replace='No internet service', value = 'No')\n",
    "telco_data['MultipleLines'] = telco_data['MultipleLines'].replace(to_replace='No phone service', value = 'No')\n",
    "telco_data['SeniorCitizen'] = telco_data['SeniorCitizen'].replace(to_replace=1, value = 'Yes')\n",
    "telco_data['SeniorCitizen'] = telco_data['SeniorCitizen'].replace(to_replace=0, value = 'No')\n",
    "\n",
    "# make tenure a categorical variable clustered by years\n",
    "def tenure_months_to_years(data):\n",
    "    if data['tenure'] <= 12 :\n",
    "        return '0-1_years'\n",
    "    elif (data['tenure'] > 12) & (data['tenure'] <= 24 ):\n",
    "        return '1-2_years'\n",
    "    elif (data['tenure'] > 24) & (data['tenure'] <= 36) :\n",
    "        return '2-3_years'\n",
    "    elif (data['tenure'] > 36) & (data['tenure'] <=48) :\n",
    "        return '3-4_years'\n",
    "    elif (data['tenure'] > 48) & (data['tenure'] <=60) :\n",
    "        return '4-5_years'\n",
    "    elif data['tenure'] > 60 :\n",
    "        return '5+_years'\n",
    "\n",
    "telco_data['tenure'] = telco_data.apply(lambda telco_data : tenure_months_to_years(telco_data),axis=1)\n",
    "\n",
    "# seperate all categorical variables from numerical variables\n",
    "categorical= telco_data.nunique()[telco_data.nunique()<7].keys().tolist()\n",
    "categorical.remove('Churn')\n",
    "numerical = [element for element in telco_data.columns if element not in categorical]\n",
    "numerical.remove('Churn')\n",
    "numerical.remove('customerID')\n",
    "\n",
    "# split categorical variables into binary ones and ones with multiple(>2) unique values\n",
    "binary = telco_data.nunique()[telco_data.nunique() ==2].keys().tolist()\n",
    "multiple = [element for element in categorical if element not in binary]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# create a label encoder and standard scaler\n",
    "label_enc = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create dummy variables for non binary categorical variables\n",
    "telco_data = pandas.get_dummies(data = telco_data, columns = multiple)\n",
    "\n",
    "# use label encoder on binary variables\n",
    "for element in binary:\n",
    "    telco_data[element] = label_enc.fit_transform(telco_data[element])\n",
    "    \n",
    "# use standard scaler on the numerical variables to normalize them\n",
    "scaled_vals = scaler.fit_transform(telco_data[numerical])\n",
    "scaled_df = pandas.DataFrame(scaled_vals, columns=numerical)\n",
    "\n",
    "# drop old non binary categorical variables. Merge dataset with dummy variable columns\n",
    "telco_data_mod = telco_data.drop(columns = numerical, axis=1)\n",
    "telco_data_mod = telco_data_mod.merge(scaled_df,how = 'left', left_index=True, right_index=True)\n",
    "\n",
    "# create the new predictors involving the dummy variables\n",
    "new_predictors = telco_data_mod.columns.tolist()\n",
    "new_predictors.remove('customerID')\n",
    "new_predictors.remove('Churn')\n",
    "\n",
    "# split the data into training and test subsets\n",
    "(tel_train,tel_test) = train_test_split(telco_data,test_size=.2)\n",
    "x_test = tel_test[new_predictors]\n",
    "y_test = tel_test[target]\n",
    "x_train = tel_train[new_predictors]\n",
    "y_train = tel_train[target]\n",
    "y_train = numpy.ravel(y_train)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base acc 0.7342150170648464\n",
      "KNN ACC= 0.7668798862828714\n",
      "[[929 129]\n",
      " [199 150]]\n",
      "dt_acc 0.7228144989339019\n",
      "[[848 210]\n",
      " [180 169]]\n",
      "rf_acc= 0.7796730632551528\n",
      "[[953 105]\n",
      " [205 144]]\n",
      "perc_acc= 0.7604832977967306\n",
      "[[967  91]\n",
      " [246 103]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# create a baseline for accuracy score\n",
    "num_churn = telco_data['Churn'].value_counts()\n",
    "base_acc = (num_churn[0])/(num_churn[0] + num_churn[1])\n",
    "\n",
    "# create a weighted knn regression model\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# train the model on the training data subsets\n",
    "knn_model.fit(x_train,(y_train))\n",
    "\n",
    "# test the models by predicting target values based on the test data subset\n",
    "knn_preds = knn_model.predict(x_test)\n",
    "\n",
    "# compute and return the mean squared error for the knn and weighted knn models\n",
    "knn_acc = accuracy_score(y_test,knn_preds)\n",
    "\n",
    "# create a decision tree for regression and train the model on training data subset\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "# test the model by predicting target values for the test data subset\n",
    "dt_preds = dt_model.predict(x_test)\n",
    "\n",
    "# compute and return the mean squared error for the decision tree\n",
    "dt_acc = accuracy_score(y_test,dt_preds)\n",
    "\n",
    "# create and fit random forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(x_train,y_train)\n",
    "\n",
    "# predict and test accuracy score on random forest model\n",
    "rf_preds = rf_model.predict(x_test)\n",
    "rf_acc = accuracy_score(y_test,rf_preds)\n",
    "\n",
    "# create and fit perceptron model\n",
    "perc_model = Perceptron()\n",
    "perc_model.fit(x_train, y_train)\n",
    "\n",
    "# predict and test accuracy score on perceptron model\n",
    "perc_preds = perc_model.predict(x_test)\n",
    "perc_acc = accuracy_score(y_test, perc_preds)\n",
    "\n",
    "print('Base acc', base_acc)\n",
    "print('KNN ACC=', knn_acc)\n",
    "print(confusion_matrix(y_test, knn_preds))\n",
    "print('dt_acc', dt_acc)\n",
    "print(confusion_matrix(y_test, dt_preds))\n",
    "print('rf_acc=', rf_acc)\n",
    "print(confusion_matrix(y_test, rf_preds))\n",
    "print(\"perc_acc=\", perc_acc)\n",
    "print(confusion_matrix(y_test, perc_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Jackson Meyer\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# tune parameters for knn. find optimal k value and make weighted\n",
    "k = 0\n",
    "optimal = False \n",
    "prev = 0\n",
    "vals = []\n",
    "while (k<=100):\n",
    "    \n",
    "    wknn_model = KNeighborsClassifier(n_neighbors = k+1, weights = \"distance\")\n",
    "    wknn_model.fit(x_train,y_train)\n",
    "    wknn_preds = wknn_model.predict(x_test)\n",
    "    acc = accuracy_score(y_test,wknn_preds)\n",
    "    vals.insert(k,acc)\n",
    "    k = k + 1\n",
    "    \n",
    "wknn_acc = max(vals)\n",
    "k_val = vals.index(max(vals))\n",
    "\n",
    "\n",
    "# tune parameters for decisoin tree. find optimal depth with entropy instead of gini\n",
    "n = 0\n",
    "vals2 = []\n",
    "while(n<=20):\n",
    "    tuned_dt_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = n+1)\n",
    "    tuned_dt_model.fit(x_train, y_train)\n",
    "    tuned_dt_preds = tuned_dt_model.predict(x_test)\n",
    "    acc2 = accuracy_score(y_test,tuned_dt_preds)\n",
    "    vals2.insert(n,acc2)\n",
    "    n = n + 1\n",
    "\n",
    "tuned_dt_acc = max(vals2)\n",
    "depth_val = vals2.index(max(vals2))\n",
    "\n",
    "\n",
    "# tune parameters for random forest. find optimal depth with entropy instead of gini\n",
    "n2 = 0\n",
    "vals3 = []\n",
    "while(n2<=50):\n",
    "    tuned_rf_model = RandomForestClassifier(max_depth=n2+1 ,criterion = 'entropy')\n",
    "    tuned_rf_model.fit(x_train, y_train)\n",
    "    tuned_rf_preds = tuned_rf_model.predict(x_test)\n",
    "    acc3 = accuracy_score(y_test,tuned_rf_preds)\n",
    "    vals3.insert(n,acc3)\n",
    "    n2 = n2 + 1\n",
    "    \n",
    "est_val = vals3.index(max(vals3))\n",
    "\n",
    "n2 = 0\n",
    "vals3 = []\n",
    "while(n2<=50):\n",
    "    tuned_rf_model = RandomForestClassifier(n_estimators=n2+1 ,criterion = 'entropy', max_depth=est_val)\n",
    "    tuned_rf_model.fit(x_train, y_train)\n",
    "    tuned_rf_preds = tuned_rf_model.predict(x_test)\n",
    "    acc3 = accuracy_score(y_test,tuned_rf_preds)\n",
    "    vals3.insert(n,acc3)\n",
    "    n2 = n2 + 1\n",
    "\n",
    "tuned_rf_acc = max(vals3)\n",
    "est_val = vals3.index(max(vals3))\n",
    "\n",
    "# test differnet values for learning rate of perceptron\n",
    "\n",
    "tuned_perc_model = Perceptron(eta0 =.2 )\n",
    "tuned_perc_model.fit(x_train, y_train)\n",
    "tuned_perc_preds = tuned_perc_model.predict(x_test)\n",
    "tuned_perc_acc = accuracy_score(y_test, tuned_perc_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base acc 0.7342150170648464\n",
      "WKNN Accuracy= 0.7967306325515281\n",
      "[[996  62]\n",
      " [233 116]]\n",
      "Tuned DT Accuracy 0.7974413646055437\n",
      "[[848 210]\n",
      " [180 169]]\n",
      "Tuned RF Accuracy= 0.8187633262260128\n",
      "[[973  85]\n",
      " [177 172]]\n",
      "Tuned Perc Accuracy= 0.7604832977967306\n",
      "[[967  91]\n",
      " [246 103]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Telecom Model Accuracy Scores')"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Base acc', base_acc)\n",
    "print('WKNN Accuracy=', wknn_acc)\n",
    "print(confusion_matrix(y_test, wknn_preds))\n",
    "print('Tuned DT Accuracy', tuned_dt_acc)\n",
    "print(confusion_matrix(y_test, dt_preds))\n",
    "print('Tuned RF Accuracy=', tuned_rf_acc)\n",
    "print(confusion_matrix(y_test, tuned_rf_preds))\n",
    "print(\"Tuned Perc Accuracy=\", tuned_perc_acc)\n",
    "print(confusion_matrix(y_test, tuned_perc_preds))\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_vals = ('Base', 'KNN','WKNN', 'DT', 'TunedDT', 'RF', 'TunedRF', \n",
    "           'Perc', 'TunedPerc')\n",
    "y_pos = numpy.arange(len(x_vals))\n",
    "percents = [100*base_acc,100*knn_acc,100*wknn_acc,100*dt_acc,\n",
    "            100*tuned_dt_acc,100*rf_acc,100*tuned_rf_acc,100*perc_acc,100*tuned_perc_acc]\n",
    "plt.bar(y_pos, percents, align='center', alpha=0.5, width=.25)\n",
    "plt.xticks(y_pos, x_vals)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Telecom Model Accuracy Scores')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
